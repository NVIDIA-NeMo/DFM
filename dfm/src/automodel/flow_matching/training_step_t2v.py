# Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import logging
import os
from typing import Dict, Tuple

import torch

from dfm.src.automodel.flow_matching.time_shift_utils import (
    compute_density_for_timestep_sampling,
)


logger = logging.getLogger(__name__)


def step_fsdp_transformer_t2v(
    scheduler,
    model,
    batch,
    device,
    bf16,
    # Flow matching parameters
    use_sigma_noise: bool = True,
    timestep_sampling: str = "uniform",
    logit_mean: float = 0.0,
    logit_std: float = 1.0,
    flow_shift: float = 3.0,
    mix_uniform_ratio: float = 0.1,
    sigma_min: float = 0.0,  # Default: no clamping (pretrain)
    sigma_max: float = 1.0,  # Default: no clamping (pretrain)
    global_step: int = 0,
) -> Tuple[torch.Tensor, Dict]:
    """
    Pure flow matching training - DO NOT use scheduler.add_noise().

    The scheduler's add_noise() uses alpha_t/sigma_t which explodes at low timesteps.
    We use simple flow matching: x_t = (1-σ)x_0 + σ*ε
    """
    debug_mode = os.environ.get("DEBUG_TRAINING", "0") == "1"
    detailed_log = global_step % 100 == 0
    summary_log = global_step % 10 == 0

    # Extract and prepare batch data
    video_latents = batch["video_latents"].to(device, dtype=bf16)
    text_embeddings = batch["text_embeddings"].to(device, dtype=bf16)

    assert video_latents.ndim in (4, 5), "Expected video_latents.ndim to be 4 or 5 "
    assert text_embeddings.ndim in (2, 3), "Expected text_embeddings.ndim to be 2 or 3 "
    # Handle tensor shapes
    if video_latents.ndim == 4:
        video_latents = video_latents.unsqueeze(0)

    if text_embeddings.ndim == 2:
        text_embeddings = text_embeddings.unsqueeze(0)

    batch_size, channels, frames, height, width = video_latents.shape

    # ========================================================================
    # Flow Matching Timestep Sampling
    # ========================================================================

    num_train_timesteps = scheduler.config.num_train_timesteps

    if use_sigma_noise:
        use_uniform = torch.rand(1).item() < mix_uniform_ratio

        if use_uniform or timestep_sampling == "uniform":
            # Pure uniform: u ~ U(0, 1)
            u = torch.rand(size=(batch_size,), device=device)
            sampling_method = "uniform"
        else:
            # Density-based sampling
            u = compute_density_for_timestep_sampling(
                weighting_scheme=timestep_sampling,
                batch_size=batch_size,
                logit_mean=logit_mean,
                logit_std=logit_std,
            ).to(device)
            sampling_method = timestep_sampling

        # Apply flow shift: σ = shift/(shift + (1/u - 1))
        u_clamped = torch.clamp(u, min=1e-5)  # Avoid division by zero
        sigma = flow_shift / (flow_shift + (1.0 / u_clamped - 1.0))

        # Clamp sigma (only if not full range [0,1])
        # Pretrain uses [0, 1], finetune uses [0.02, 0.55]
        if sigma_min > 0.0 or sigma_max < 1.0:
            sigma = torch.clamp(sigma, sigma_min, sigma_max)
        else:
            sigma = torch.clamp(sigma, 0.0, 1.0)

    else:
        # Simple uniform without shift
        u = torch.rand(size=(batch_size,), device=device)

        # Clamp sigma (only if not full range [0,1])
        if sigma_min > 0.0 or sigma_max < 1.0:
            sigma = torch.clamp(u, sigma_min, sigma_max)
        else:
            sigma = u
        sampling_method = "uniform_no_shift"

    # ========================================================================
    # Manual Flow Matching Noise Addition
    # ========================================================================

    # Generate noise
    noise = torch.randn_like(video_latents, dtype=torch.float32)

    # CRITICAL: Manual flow matching (NOT scheduler.add_noise!)
    # x_t = (1 - σ) * x_0 + σ * ε
    sigma_reshaped = sigma.view(-1, 1, 1, 1, 1)
    noisy_latents = (1.0 - sigma_reshaped) * video_latents.float() + sigma_reshaped * noise

    # Timesteps for model [0, 1000]
    timesteps = sigma * num_train_timesteps

    # ====================================================================
    # DETAILED LOGGING
    # ====================================================================
    if detailed_log or debug_mode:
        logger.info("\n" + "=" * 80)
        logger.info(f"[STEP {global_step}] MANUAL FLOW MATCHING")
        logger.info("=" * 80)
        logger.info("[WARNING] NOT using scheduler.add_noise() - it explodes!")
        logger.info("[INFO] Using manual: x_t = (1-σ)x_0 + σ*ε")
        logger.info("")
        logger.info(f"[SAMPLING] Method: {sampling_method}")
        logger.info(f"[FLOW] Shift: {flow_shift}")
        logger.info(f"[BATCH] Size: {batch_size}")
        logger.info("")
        logger.info(f"[U] Range: [{u.min():.4f}, {u.max():.4f}]")
        if u.numel() > 1:
            logger.info(f"[U] Mean: {u.mean():.4f}, Std: {u.std():.4f}")
        else:
            logger.info(f"[U] Value: {u.item():.4f}")
        logger.info("")
        logger.info(f"[SIGMA] Range: [{sigma.min():.4f}, {sigma.max():.4f}]")
        if sigma.numel() > 1:
            logger.info(f"[SIGMA] Mean: {sigma.mean():.4f}, Std: {sigma.std():.4f}")
        else:
            logger.info(f"[SIGMA] Value: {sigma.item():.4f}")
        logger.info("")
        logger.info(f"[TIMESTEPS] Range: [{timesteps.min():.2f}, {timesteps.max():.2f}]")
        logger.info("")
        logger.info(f"[WEIGHTS] Clean: {(1 - sigma_reshaped).squeeze().cpu().numpy()}")
        logger.info(f"[WEIGHTS] Noise: {sigma_reshaped.squeeze().cpu().numpy()}")
        logger.info("")
        logger.info(f"[RANGES] Clean latents: [{video_latents.min():.4f}, {video_latents.max():.4f}]")
        logger.info(f"[RANGES] Noise:         [{noise.min():.4f}, {noise.max():.4f}]")
        logger.info(f"[RANGES] Noisy latents: [{noisy_latents.min():.4f}, {noisy_latents.max():.4f}]")

        # Sanity check
        max_expected = (
            max(
                abs(video_latents.max().item()),
                abs(video_latents.min().item()),
                abs(noise.max().item()),
                abs(noise.min().item()),
            )
            * 1.5
        )
        if abs(noisy_latents.max()) > max_expected or abs(noisy_latents.min()) > max_expected:
            logger.info(f"\n⚠️  WARNING: Noisy range seems large! Expected ~{max_expected:.1f}")
        else:
            logger.info("\n✓ Noisy latents range is reasonable")
        logger.info("=" * 80 + "\n")

    elif summary_log:
        logger.info(
            f"[STEP {global_step}] σ=[{sigma.min():.3f},{sigma.max():.3f}] | "
            f"t=[{timesteps.min():.1f},{timesteps.max():.1f}] | "
            f"noisy=[{noisy_latents.min():.1f},{noisy_latents.max():.1f}] | "
            f"{sampling_method}"
        )

    # Convert to bf16
    noisy_latents = noisy_latents.to(bf16)
    timesteps_for_model = timesteps.to(bf16)

    # ========================================================================
    # Forward Pass
    # ========================================================================

    try:
        model_pred = model(
            hidden_states=noisy_latents,
            timestep=timesteps_for_model,
            encoder_hidden_states=text_embeddings,
            return_dict=False,
        )

        if isinstance(model_pred, tuple):
            model_pred = model_pred[0]

    except Exception as e:
        logger.info(f"[ERROR] Forward pass failed: {e}")
        logger.info(
            f"[DEBUG] noisy_latents: {noisy_latents.shape}, range: [{noisy_latents.min()}, {noisy_latents.max()}]"
        )
        logger.info(
            f"[DEBUG] timesteps: {timesteps_for_model.shape}, range: [{timesteps_for_model.min()}, {timesteps_for_model.max()}]"
        )
        raise

    # ========================================================================
    # Target: Flow Matching Velocity
    # ========================================================================

    # Flow matching target: v = ε - x_0
    target = noise - video_latents.float()

    # ========================================================================
    # Loss with Flow Weighting
    # ========================================================================

    loss = torch.nn.functional.mse_loss(model_pred.float(), target.float(), reduction="none")

    # Flow weight: w = 1 + shift * σ
    loss_weight = 1.0 + flow_shift * sigma
    loss_weight = loss_weight.view(-1, 1, 1, 1, 1).to(device)

    unweighted_loss = loss.mean()
    weighted_loss = (loss * loss_weight).mean()

    # Safety check
    if torch.isnan(weighted_loss) or weighted_loss > 100:
        logger.info(f"[ERROR] Loss explosion! Loss={weighted_loss.item():.3f}")
        logger.info("[DEBUG] Stopping training - check hyperparameters")
        raise ValueError(f"Loss exploded: {weighted_loss.item()}")

    # ====================================================================
    # LOSS LOGGING
    # ====================================================================
    if detailed_log or debug_mode:
        logger.info("=" * 80)
        logger.info(f"[STEP {global_step}] LOSS DEBUG")
        logger.info("=" * 80)
        logger.info("[TARGET] Flow matching: v = ε - x_0")
        logger.info(f"[PREDICTION] Scheduler type (inference only): {type(scheduler).__name__}")
        logger.info("")
        logger.info(f"[RANGES] Model pred: [{model_pred.min():.4f}, {model_pred.max():.4f}]")
        logger.info(f"[RANGES] Target (v): [{target.min():.4f}, {target.max():.4f}]")
        logger.info("")
        logger.info(f"[WEIGHTS] Formula: 1 + {flow_shift} * σ")
        logger.info(f"[WEIGHTS] Range: [{loss_weight.min():.4f}, {loss_weight.max():.4f}]")
        if loss_weight.numel() > 1:
            logger.info(f"[WEIGHTS] Mean: {loss_weight.mean():.4f}")
        else:
            logger.info(f"[WEIGHTS] Value: {loss_weight.mean():.4f}")
        logger.info("")
        logger.info(f"[LOSS] Unweighted: {unweighted_loss.item():.6f}")
        logger.info(f"[LOSS] Weighted:   {weighted_loss.item():.6f}")
        logger.info(f"[LOSS] Impact:     {(weighted_loss / max(unweighted_loss, 1e-8)):.3f}x")
        logger.info("=" * 80 + "\n")

    elif summary_log:
        logger.info(
            f"[STEP {global_step}] Loss: {weighted_loss.item():.6f} | "
            f"w=[{loss_weight.min():.2f},{loss_weight.max():.2f}]"
        )

    # Metrics
    metrics = {
        "loss": weighted_loss.item(),
        "unweighted_loss": unweighted_loss.item(),
        "sigma_min": sigma.min().item(),
        "sigma_max": sigma.max().item(),
        "sigma_mean": sigma.mean().item(),
        "weight_min": loss_weight.min().item(),
        "weight_max": loss_weight.max().item(),
        "timestep_min": timesteps.min().item(),
        "timestep_max": timesteps.max().item(),
        "noisy_min": noisy_latents.min().item(),
        "noisy_max": noisy_latents.max().item(),
        "sampling_method": sampling_method,
    }

    return weighted_loss, metrics
